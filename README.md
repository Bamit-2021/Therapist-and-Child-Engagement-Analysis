# Therapist-and-Child-Engagement-Analysis

These are Python libraries like OpenCV for handling videos, NumPy for numerical operations, Pillow for image processing, PyTorch for deep learning tasks, and Matplotlib for visualizations. It employs these libraries to perform various functions like tracking gazes of individuals, detecting object interactions, and predicting emotions from video frames. Additionally, a custom EmotionPredictor class is utilized for emotion prediction. This aims to process a video capturing an ABA therapy session, analyzing behaviors and interactions between a child and therapist. Through a series of steps, it extracts frames, analyzes them, predicts emotions, and visualizes the results overlaid on the video frames.

This aims to analyze a video capturing an ABA therapy session, performing various tasks such as tracking the gazes of the child and therapist, detecting object interactions, predicting emotions, and visualizing the predictions overlaying the video frames. Initially, the video frames are preprocessed to extract individual frames. Then, for each frame, the script tracks the gazes of both the child and therapist, detects object interactions, and predicts emotions using an EmotionPredictor class. Subsequently, it visualizes the predictions by plotting the gaze points and annotating the detected interactions and predicted emotions onto the video frames. Finally, the annotated frames are compiled into an output video. However, the code has some issues, such as redefining the `main()` function and using incorrect arguments in the `compile_video()` function, which should be addressed to ensure correct functionality.
